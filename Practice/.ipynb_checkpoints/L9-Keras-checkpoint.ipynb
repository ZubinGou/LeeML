{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 129us/step - loss: 0.0908 - accuracy: 0.1051\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0900 - accuracy: 0.1092\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0900 - accuracy: 0.1091\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0900 - accuracy: 0.1100\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1126\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0899 - accuracy: 0.1139\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1116\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1159\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1146\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0899 - accuracy: 0.1188\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1113\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1170\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1156\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1313\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0899 - accuracy: 0.1145\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.0899 - accuracy: 0.1153\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.0899 - accuracy: 0.1228\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0899 - accuracy: 0.1236\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1173\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0899 - accuracy: 0.1222\n",
      "10000/10000 [==============================] - 0s 6us/step\n",
      "Train ACC:  0.11270000040531158\n",
      "10000/10000 [==============================] - 0s 4us/step\n",
      "Test ACC:  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='sigmoid'))\n",
    "model.add(Dense(units=689,activation='sigmoid'))\n",
    "model.add(Dense(units=689,activation='sigmoid'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 64us/step - loss: 0.8478 - accuracy: 0.7631\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.3290 - accuracy: 0.9014\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.2367 - accuracy: 0.9306\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.1920 - accuracy: 0.9437\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 1s 70us/step - loss: 0.1573 - accuracy: 0.9540\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 1s 119us/step - loss: 0.1291 - accuracy: 0.9649\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.1107 - accuracy: 0.9683\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0931 - accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 1s 58us/step - loss: 0.0746 - accuracy: 0.9807\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.0636 - accuracy: 0.9850\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.0540 - accuracy: 0.9874\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 1s 141us/step - loss: 0.0434 - accuracy: 0.9902\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 1s 69us/step - loss: 0.0345 - accuracy: 0.9934\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 1s 62us/step - loss: 0.0295 - accuracy: 0.9944\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.0253 - accuracy: 0.9953\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.0208 - accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 1s 95us/step - loss: 0.0176 - accuracy: 0.9977\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 1s 63us/step - loss: 0.0136 - accuracy: 0.9985\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0113 - accuracy: 0.9992\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0096 - accuracy: 0.9996\n",
      "10000/10000 [==============================] - 0s 7us/step\n",
      "Train ACC:  0.9998000264167786\n",
      "10000/10000 [==============================] - 0s 4us/step\n",
      "Test ACC:  0.9544000029563904\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    # 注释调上两行，不使用normalization，loss卡住\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "# sigmoid -> relu ， loss: 87 -> 95\n",
    "\n",
    "# for i in range(10):\n",
    "#     model.add(Dense(units=689,activation='relu'))\n",
    "# 设置多层NN，因Gradient Vanish loss卡住\n",
    "\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 更改用交叉熵 acc 11 -> 87\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "# batch_size = 100 合适\n",
    "# 1 GPU无法并行运算，太慢\n",
    "# 10000 loss卡住\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 7800/10000 [======================>.......] - ETA: 0s - loss: 0.4880 - accuracy: 0.8545"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "# K.set_epsilon(1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# SGD -> adam 尚未解决的bug：本机adam与categorical_crossentropy无法一起work\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 1.8757 - accuracy: 0.3369\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 1.0027 - accuracy: 0.6494\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.7174 - accuracy: 0.7671\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.5916 - accuracy: 0.8120\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.5101 - accuracy: 0.8431\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.4546 - accuracy: 0.8614\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.4102 - accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.3865 - accuracy: 0.8841\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.3557 - accuracy: 0.8970\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3326 - accuracy: 0.9052\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.3050 - accuracy: 0.9076\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.2944 - accuracy: 0.9143\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.2794 - accuracy: 0.9186\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2615 - accuracy: 0.9226\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.2506 - accuracy: 0.9268\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 0.2438 - accuracy: 0.9290\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.2343 - accuracy: 0.9315\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.2316 - accuracy: 0.9319\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2153 - accuracy: 0.9351\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.1997 - accuracy: 0.9371\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Train ACC:  0.9781000018119812\n",
      "10000/10000 [==============================] - 0s 8us/step\n",
      "Test ACC:  0.6128000020980835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    x_test = np.random.normal(x_test)\n",
    "    # 加上noise，过拟合，结果烂掉 43%\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "# 加上dropout，正确率61%\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
