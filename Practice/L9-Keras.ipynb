{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.0908 - accuracy: 0.1010\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 0.0900 - accuracy: 0.1059\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0900 - accuracy: 0.1044\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0900 - accuracy: 0.1078\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0900 - accuracy: 0.1097\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0900 - accuracy: 0.1108\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.0900 - accuracy: 0.1126\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0900 - accuracy: 0.1127\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0899 - accuracy: 0.1112\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0899 - accuracy: 0.1156\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0899 - accuracy: 0.1149\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0899 - accuracy: 0.1145\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0899 - accuracy: 0.1182\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0899 - accuracy: 0.1169\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0899 - accuracy: 0.1134\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0899 - accuracy: 0.1147\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0899 - accuracy: 0.1124\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.0899 - accuracy: 0.1180\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0899 - accuracy: 0.1170\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0899 - accuracy: 0.1147\n",
      "10000/10000 [==============================] - 0s 6us/step\n",
      "Train ACC:  0.11270000040531158\n",
      "10000/10000 [==============================] - 0s 4us/step\n",
      "Test ACC:  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path.abspath('./dataset/mnist.npz'))\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='sigmoid'))\n",
    "model.add(Dense(units=689,activation='sigmoid'))\n",
    "model.add(Dense(units=689,activation='sigmoid'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.8427 - accuracy: 0.7718\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.3258 - accuracy: 0.9079\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.2476 - accuracy: 0.9281\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1952 - accuracy: 0.9416\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1529 - accuracy: 0.9551\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1329 - accuracy: 0.9616\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.1099 - accuracy: 0.9698\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0930 - accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0759 - accuracy: 0.9804\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0631 - accuracy: 0.9841\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0516 - accuracy: 0.9877\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0439 - accuracy: 0.9905\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0359 - accuracy: 0.9922\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0295 - accuracy: 0.9947\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0244 - accuracy: 0.9961\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.0202 - accuracy: 0.9971\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0167 - accuracy: 0.9980\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0135 - accuracy: 0.9987\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.0109 - accuracy: 0.9993\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0090 - accuracy: 0.9997\n",
      "10000/10000 [==============================] - 0s 7us/step\n",
      "Train ACC:  0.9998000264167786\n",
      "10000/10000 [==============================] - 0s 6us/step\n",
      "Test ACC:  0.955299973487854\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path.abspath('./dataset/mnist.npz'))\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    # 注释调上两行，不使用normalization，loss卡住\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "# sigmoid -> relu ， loss: 87 -> 95\n",
    "\n",
    "# for i in range(10):\n",
    "#     model.add(Dense(units=689,activation='relu'))\n",
    "# 设置多层NN，因Gradient Vanish loss卡住\n",
    "\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 更改用交叉熵 acc 11 -> 87\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "# batch_size = 100 合适\n",
    "# 1 GPU无法并行运算，太慢\n",
    "# 10000 loss卡住\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 61us/step - loss: 0.4459 - accuracy: 0.8682\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1470 - accuracy: 0.9563\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0744 - accuracy: 0.9768\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0570 - accuracy: 0.9808\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0433 - accuracy: 0.9862\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0267 - accuracy: 0.9925\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0324 - accuracy: 0.9891\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0136 - accuracy: 0.9965\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0346 - accuracy: 0.9899\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0265 - accuracy: 0.9930\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.0155 - accuracy: 0.9945\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0107 - accuracy: 0.9959\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0180 - accuracy: 0.9942\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.0200 - accuracy: 0.9938\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0140 - accuracy: 0.9957\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.0196 - accuracy: 0.9939\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 4.1999e-04 - accuracy: 0.9999\n",
      "10000/10000 [==============================] - 0s 6us/step\n",
      "Train ACC:  1.0\n",
      "10000/10000 [==============================] - 0s 5us/step\n",
      "Test ACC:  0.9674000144004822\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path.abspath('./dataset/mnist.npz'))\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "# K.set_epsilon(1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# SGD -> adam \n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 1.8757 - accuracy: 0.3369\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 1.0027 - accuracy: 0.6494\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.7174 - accuracy: 0.7671\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.5916 - accuracy: 0.8120\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.5101 - accuracy: 0.8431\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.4546 - accuracy: 0.8614\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.4102 - accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.3865 - accuracy: 0.8841\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.3557 - accuracy: 0.8970\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3326 - accuracy: 0.9052\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.3050 - accuracy: 0.9076\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.2944 - accuracy: 0.9143\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.2794 - accuracy: 0.9186\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2615 - accuracy: 0.9226\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 0.2506 - accuracy: 0.9268\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 1s 55us/step - loss: 0.2438 - accuracy: 0.9290\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.2343 - accuracy: 0.9315\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.2316 - accuracy: 0.9319\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2153 - accuracy: 0.9351\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.1997 - accuracy: 0.9371\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "Train ACC:  0.9781000018119812\n",
      "10000/10000 [==============================] - 0s 8us/step\n",
      "Test ACC:  0.6128000020980835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    x_test = np.random.normal(x_test)\n",
    "    # 加上noise，过拟合，结果烂掉 43%\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=689, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(units=689,activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "# 加上dropout，正确率61%\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "result_train = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print('Train ACC: ', result_train[1])\n",
    "\n",
    "result_test = model.evaluate(x_test, y_test, batch_size=10000)\n",
    "\n",
    "print('Test ACC: ', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
